---
title: "T2DD ETL"
author: "Pieta"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{T2DD ETL}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

This is the processing and ETL of the first batch of data for the Type 2 Diabetes Drugs Project

## Method

Load the data into a temporary duckdb database and then perform the cleaning processes once loaded as
this is easier than multiple passes on the same datafile.

Set up the temporary paths to the raw files.

### Paths

```{r}
require(cprdaurumtools)
require(tidyverse)
require(duckdb)
require(plib)
homeDir <- Sys.getenv("HOME")
projRoot <- file.path(homeDir,"Projects")
batch <- 1 
pdir <- file.path(projRoot,"t2dd",".data")
rdir <- file.path(projRoot,"t2dd","reference")
ddir <- file.path(pdir,"aurum",paste0("batch",batch))
cdir <- file.path(projRoot,"refdata","aurum","202303_Lookups_CPRDAurum")
ldir <- file.path(pdir,"linked")
hdir <- file.path(ldir,"hes")
odir <- file.path(ldir,"ons")
idir <- file.path(ldir,"ons")
dbif <- file.path(pdir,"t2dd_prep.duckdb")
dbof <- file.path(pdir,"t2dd.duckdb")
```

### Load Patients

```{r}
pddir <- file.path(ddir,"Patient")
load_patients(pdir=pddir,dbf=dbif,ow=F)
str_sql <- "SELECT patid FROM patients;"
dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
dbListTables(dbi) 
patids <- dbGetQuery(dbi,str_sql) %>% as_tibble() %>% pull(patid)
duckdb::dbDisconnect(dbi)
pddir <- file.path(ddir,"Observation")
load_obs(pddir=pddir,dbf=dbif,ow=F)
pddir <- file.path(ddir,"DrugIssue")
load_drugissues(pddir=pddir,dbf=dbif,ow=F)
pddir <- file.path(ddir,"Consultation")
load_cons(pddir=pddir,dbf=dbif,ow=F)
pddir <- file.path(ddir,"Referral")
load_referrals(pddir=pddir,dbf=dbif,ow=F)
pddir <- file.path(ddir,"Problem")
load_probs(pddir=pddir,dbf=dbif,ow=F)
pddir <- file.path(ddir,"Staff")
load_staff(pddir=pddir,dbf=dbif,ow=F)
pddir <- file.path(ddir,"Practice")
load_practice(pddir=pddir,dbf=dbif,ow=F)
load_hesfiles(pddir=hdir,dbf=dbif,tad="21_001631.*",pats=patids,ow=F)
load_imdfiles(pddir=idir,dbf=dbif,tad="21_001631.*",pats=patids,ow=F)
load_onsfiles(pddir=odir,dbf=dbif,tad="21_001631.*",pats=patids,ow=F)
load_cprdfiles(pddir=cdir,dbf=dbif,ow=F)
```

## Pre-processing

At this point we have loaded a lot of data into the pre-processing database the next step is to transfer
processed records to the analysis database

### Complete Cases

Possibly we need to join the patient table with the HES patient table and their ONS and IMD data

```{r}
linkage_sql <- str_c("
  SELECT
    p.patid,
    h.patid AS apc_id,
    i.patid AS imd_id,
    o.patid AS ons_id
  FROM 
    patients AS p
  LEFT JOIN
    hes_patient AS h
    ON p.patid=h.patid
  LEFT JOIN 
    patient_2019_imd AS i
    ON p.patid=i.patid
  LEFT JOIN
    death_patient AS o
    ON p.patid=o.patid")

dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
linkages <- dbGetQuery(dbi,linkage_sql) %>% tibble()
duckdb::dbDisconnect(dbi)
linkages <- linkages %>% pivot_longer(-patid,names_to="linkage",values_to="linked") %>%
  mutate(linked=ifelse(!is.na(linked),1,0))
linkages %>% group_by(linkage) %>% summarise(N=sum(linked),.groups="drop") %>% 
  display_data(disp=T)
```

## Baseline Covariates

There are lots of covariates for this project. This needs turning into a function

```{r}
dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
if(!"baseline_codes"%in%dbListTables(dbi)){
  prdir <- file.path(projRoot,"t2dd","reference")
  cvfile <- file.path(prdir,"xls","baseline_covariates_codes.xlsx")
  cvs <- readxl::excel_sheets(cvfile)[-1]
  names(cvs) <- cvs
  cvtab <- lapply(cvs,function(sn) readxl::read_excel(cvfile,sheet=sn)) %>% 
    plyr::ldply() %>% tibble() %>% rename(cv=.id) %>% select(cv,medcodeid) 
  dbWriteTable(dbi,"baseline_codes",cvtab,overwrite=T)
}
duckdb::dbDisconnect(dbi,shutdown=T)

gen_baselines(dbf=dbif,tabname="baseline_codes")

ext_bl_sql <- str_c("SELECT DISTINCT * FROM covariate_observations")

dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
cv_vals <- dbGetQuery(dbi,ext_bl_sql) %>% tibble()
dbDisconnect(dbi)

cv_vals %>% group_by(baseline) %>% summarise(N=n(),.groups="drop") %>% display_data(disp=T)
```

## Index Dates

### Drug of interest

These relate to the medications so perhaps pull a medications table

```{r}
dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
if(!"exposure_codes"%in%dbListTables(dbi)){
  prdir <- file.path(projRoot,"t2dd","reference")
  cvfile <- file.path(prdir,"xls","Aurum_medication_codes_exposures.xlsx")
  cvs <- readxl::excel_sheets(cvfile)[-1]
  mec <- readxl::read_excel(cvfile,sheet=1,col_types="text") %>% 
  names(mec) <- tolower(names(mec))
  dbWriteTable(dbi,"exposure_codes",mec,overwrite=T)
}
duckdb::dbDisconnect(dbi,shutdown=T)

gen_drugexposure(dbf=dbif,newtab="drug_exposures",tabname="exposure_codes",substancefield="substancelink")

ext_dex_sql <- str_c("SELECT * FROM drug_exposures")

dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
dex_vals <- dbGetQuery(dbi,ext_dex_sql) %>% tibble()
dbDisconnect(dbi)

dex_vals %>% group_by(substance) %>% summarise(N=n(),.groups="drop") %>% display_data(disp=T)
```

So how many patients have exposures

```{r}
exp_sql <- str_c("
  SELECT DISTINCT
    p.patid,
    p.yob,
    COALESCE(t.substance,'none') AS substance,
    indexdate,
    1 AS cohort,
    YEAR(CAST(indexdate AS DATE)) - p.yob AS indexage
  FROM
    patients AS p
  LEFT JOIN(
    SELECT DISTINCT
      patid,
      substancelink AS substance,
      FIRST(d.issuedate) OVER (PARTITION BY d.patid, e.substancelink ORDER BY d.issuedate) AS indexdate
    FROM 
      drug_issues AS d
    INNER JOIN
      exposure_codes AS e
      ON e.prodcodeid=d.prodcodeid) AS t
    ON t.patid=p.patid")
    
dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
dex_vals <- dbGetQuery(dbi,exp_sql) %>% tibble()
dbDisconnect(dbi)

dex_vals %>% mutate(indexdate=lubridate::ymd(indexdate)) %>% dplyr::filter(substance!="none") %>%
  group_by(substance) %>% summarise(N=n(),mediandate=median(indexdate),.groups="drop") %>%
  display_data(disp=T)
exppat <- dex_vals %>% dplyr::filter(substance!="none")  %>% pull(patid) %>% unique()
length(exppat)
```

### Diabetes 2 dates

```{r}
dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
if(!"type2codes"%in%dbListTables(dbi)){
  prdir <- file.path(projRoot,"t2dd","reference")
  t2dcodesfile <- file.path(prdir,"xls","Aurum_diabetes_type_2_codes.xlsx")
  t2dcodes <- readxl::read_excel(t2dcodesfile,col_type="text") %>%
    select(MedCodeId,Term,SnomedCTConceptId) 
  names(t2dcodes) <- tolower(names(t2dcodes))
  dbWriteTable(dbi,"type2codes",t2dcodes,over=T)
}
dbDisconnect(dbi)

idx_sql <- str_c("
  SELECT DISTINCT
    p.patid,
    p.yob,
    p.regstartdate,
    p.regenddate,
    p.cprd_ddate,
    p.emis_ddate,
    t.indexdate
  FROM 
    patients AS p
  LEFT JOIN(
    SELECT DISTINCT
      o.patid,
      FIRST(o.obsdate) OVER (PARTITION BY o.patid ORDER BY o.obsdate) AS indexdate
    FROM
      patients AS r
    INNER JOIN
      observations AS o
      ON r.patid=o.patid
    INNER JOIN
      type2codes AS c
      ON c.medcodeid = o.medcodeid
    WHERE 
      YEAR(CAST(o.obsdate AS DATE)) > r.yob) AS t
    ON t.patid=p.patid")

dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
idx_vals <- dbGetQuery(dbi,idx_sql) %>% tibble()
dbDisconnect(dbi)

idx_vals %>% mutate(iyear=lubridate::year(lubridate::ymd(indexdate))) %>%
  dplyr::filter(!is.na(iyear)) %>% ggplot() + geom_bar(aes(x=iyear))
t2pats <- idx_vals %>% mutate(iyear=lubridate::year(lubridate::ymd(indexdate))) %>%
  dplyr::filter(!is.na(iyear)) %>% pull(patid) 
length(t2pats)
intersect(t2pats,exppat) %>% length()
```

This is puzzling I need to check if people with no diabetes codes already have it at start of study
period. It is insane not just puzzling

A quick sanity check shows that we have about 225 observations per patient. That doesn't really seem
enough to me. We are also only interested in patients with diabetes 2 codes 


So we have a sanity check for 

```{r}
sanityfile <- file.path(pdir,"t2dd_Define_results.txt")
sanitydata <- read_tsv(sanityfile,col_type=cols(.default=col_character())) %>% 
  mutate(indexdate=lubridate::dmy(indexdate)) %>% rename(latestindex=indexdate)
sanitydata %>% dplyr::filter(patid%in%patids) %>% nrow()
```

That means these are all cases well that is a relief, compare index dates

```{r}
sanitycheck <- sanitydata %>% inner_join(idx_vals,by="patid")
sanitycheck %>% dplyr::filter(is.na(indexdate)) %>% display_data(disp=T)
sanitycheck %>% dplyr::filter(latestindex!=indexdate) %>% display_data(disp=T)
```

This is getting stranger where are these missing codes

Well that is a relief too. Only part of the data was there.

```{r}
if(F){
  t2codesfiles <- file.path(projRoot,"t2dd","reference","txt","t2dcodes.txt")
  t2codes <- read_tsv(t2codesfiles,col_type=cols(.default=col_character())) %>% select(MedCodeId)
  t2dc <- t2dcodes %>% full_join(t2codes, by="MedCodeId") %>% arrange(desc(MedCodeId))
  dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
  dbExecute(dbi,"DROP TABLE observations")
  dbWriteTable(dbi,"type2codes",t2dc,over=T)
  dbDisconnect(dbi,shutdown=T)
}
```

Is this the problem of missing data from the CPRD extract. I can create a list of patients and re-extract

```{r}
if(F){
  dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
  patidlist <- dbGetQuery(dbi,"SELECT patid FROM patients")
  patidlist %>% write_tsv(file=file.path(pdir,"batch1_patients.txt"))
  dbDisconnect(dbi,shutdown=T)
}
```

This means that the index dates are suspect for a large number of patients.

Index date of diabetes diagnosis

- _indexdate_:  date of first acceptable record of a diabetes code against that patid
    - _check if before YOB_: 
        - __y__ reject get next date 
        - __n__ _check if before regstartdate_: not sure here. 
            - __y__ if before 2005/01/01 
                - __n__ set to regstartdate
                - __y__ set to 2005/01/01
            - __n__ if defore 2005/01/01
                - __n__ use as indexdate
                - __y__ set to 2005/01/01

```{r}
gen_diagnosis_index(dbif,diag_tab="type2codes",idate_tab="baseline_date",sp_start="2005-01-01",
                    sp_end="2022-12-31")


dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
cleanidates <- dbGetQuery(dbi,"SELECT * FROM baseline_date") %>% tibble()
dbDisconnect(dbi,shutdown=T)

cleanidates %>% mutate(iyear=lubridate::year(lubridate::ymd(basedate))) %>% 
   ggplot() + geom_bar(aes(x=iyear))

cleanidates %>% dplyr::filter(is.na(basedate)) %>% display_data(disp=T)
```

There are 180 folk in here who appear not to have any unambiguous diabetes start date. Are any of these
patients on the new drugs or can we just drop them

```{r}
problemids <- cleanidates %>% dplyr::filter(is.na(basedate)) %>% pull(patid)
dex_vals %>% dplyr::filter(substance!="none" & patid %in% problemids) %>% nrow()
```

One of the patients. I think we can drop them all but I will double check

## Build MPI

Perhaps the best thing to do is build a master patient index using the patient details then their
baseline date, their exposure/pseudo-exposure date and their linkage status.

```{r}
sort( sapply(mget(ls()),object.size) ) 
rm(list=c("linkages","sanitydata","cv_vals","dex_vals","idx_vals","t2pats","exppat","cleanidates",
          "sanitycheck","patids"))
gc()
sort( sapply(mget(ls()),object.size) ) 
extract_mpi(dbif,dbof)
```

Extract the baseline measurements

What are the baseline measurements. Between the diagnosis of diabetes and the introduction of the
medication.

```{r}
dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
if(!"drug_dates"%in%dbListTables(dbi)){
  drugintrofile <- file.path(rdir,"txt","drug_intro_dates.txt")
  drugintro <- read_tsv(drugintrofile) %>% mutate(Date=lubridate::dmy(Date)) %>% rename(idate=Date)
  names(drugintro) <- tolower(names(drugintro))
  dbWriteTable(dbi,"drug_dates",drugintro,over=T)
  reg <- dbGetQuery(dbi,"SELECT * FROM aurum_region")
  reg
}
dbDisconnect(dbi,shutdown=T)
```

```{r}
if(F){
  dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
  dbListTables(dbi)
  dbListFields(dbi,"baseline_codes")
  dbDisconnect(dbi)
}
.get_blm <- function(dbf,db=T){
  if(db){
    dbf <- dbif
  }

  blm_sql <- str_c("
    SELECT
      b.patid,
      c.cv,
      COUNT(m.value) AS n,
      AVG(CAST(m.value AS REAL)) AS baseline
    FROM 
      baseline_date AS b
    INNER JOIN
      observations AS m
      ON m.patid=b.patid
    INNER JOIN
      baseline_codes AS c
      ON c.medcodeid=m.medcodeid
    WHERE   
      m.obsdate <= b.basedate AND
      DATEDIFF('year',CAST(m.obsdate AS DATE),CAST(b.basedate AS DATE)) <= 10 AND
      m.value IS NOT NULL
    GROUP BY
      b.patid,
      c.cv,
    ORDER BY
      b.patid,
      c.cv")

  dbi <- duckdb::dbConnect(duckdb::duckdb(),dbif)
  blm <- dbGetQuery(dbi,blm_sql)
  dbDisconnect(dbi)
  blmv <- blm %>% select(-n) %>% pivot_wider(names_from="cv",values_from="baseline",values_fill=NULL)
  bln <- blm %>% select(-baseline) %>% pivot_wider(names_from="cv",values_from="n",values_fill=0)
  bln
}

```

Need to create intervention dates for those who have not had any of the medications for each of the
medication introduction date


```{r echo=F,eval=F}
homeDir <- Sys.getenv("HOME")
inputpath <- file.path(homeDir,"GitLab","cprdaurumtools","vignettes")
inputFile <- file.path(inputpath,"t2dd_etl.Rmd")
if(Sys.info()["nodename"]=="S600"){
  noteDir <- file.path("/var","www","html","uol","t2dd")
}else{
  noteDir <- file.path(homeDir,"Notes","uol","t2dd")
}

fdisp <- rmarkdown::render(inputFile,encoding=encoding,output_dir=noteDir,clean=T)
system2("firefox", args=fdisp, stderr=NULL,wait=F)
                                                                |~                                                                                                               
355 ## Build MPI                             ```
